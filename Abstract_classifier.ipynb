{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Classification of Abstracts (Math and Physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import feedparser\n",
    "import random\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from statistics import mode\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_abstracts(search_query, start, max_results):\n",
    "    # calling the api: http://export.arxiv.org/api/{method_name}?{parameters}\n",
    "    base_url = 'http://export.arxiv.org/api/query?';\n",
    "\n",
    "    query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
    "                                                     start,\n",
    "                                                     max_results)\n",
    "\n",
    "    feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "    feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "\n",
    "    # perform a GET request using the base_url and query\n",
    "    response = urllib.request.urlopen(base_url+query).read()\n",
    "    feed = feedparser.parse(response)\n",
    "    return feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def tokenize_abst(area, abst_list):\n",
    "    tokenized = []\n",
    "    add_words = []\n",
    "    for abst in abst_list:\n",
    "        words = [ w.lower() for w in word_tokenize(abst) if not w in stop_words]\n",
    "        tokenized.append((words,area))\n",
    "        add_words += words\n",
    "    return tokenized, add_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_selection(abstracts):\n",
    "    words = set(abstracts)\n",
    "    features = {}\n",
    "    for i in word_features:\n",
    "        features[i] = (i in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scikit_classifier(name, classf, train_set, test_set):\n",
    "    sele_classifier = SklearnClassifier(classf())\n",
    "    sele_classifier.train(train_set)\n",
    "    print(name, \"accuracy percent:\", (nltk.classify.accuracy(sele_classifier, test_set))*100)\n",
    "    return sele_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_files():\n",
    "    physics_feed = search_abstracts('all:physics', start = 1500, max_results = 50)\n",
    "    math_feed = search_abstracts('all:math', start = 1500, max_results = 50)\n",
    "\n",
    "    physics_abstracts = [entry.summary for entry in physics_feed.entries]\n",
    "    math_abstracts = [entry.summary for entry in math_feed.entries]\n",
    "\n",
    "    all_abst = physics_abstracts + math_abstracts\n",
    "\n",
    "    random.shuffle(all_abst)\n",
    "\n",
    "    # get current directory\n",
    "    current_dir = os.getcwd()\n",
    "    new_folder_path = current_dir+os.sep+'math+physics_files'\n",
    "    try:\n",
    "        os.mkdir(new_folder_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    for abstr in range(len(all_abst)):\n",
    "        name = 'file'+'_'+str(abstr)+'.txt'\n",
    "        with open(new_folder_path+os.sep+name, 'w') as f:\n",
    "            f.write(all_abst[abstr])\n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_abstract(path_to_files, classifier):\n",
    "    for file in os.listdir(path_to_files):\n",
    "        with open(path_to_files+os.sep+file, 'r') as f:\n",
    "            abstr_words = [w.lower() for w in word_tokenize(f.read())]\n",
    "\n",
    "            abstract_features = feature_selection(abstr_words)\n",
    "\n",
    "            abstr_class = selected_classifier.classify(abstract_features)\n",
    "\n",
    "            abstr_class_path = path_to_files+os.sep+abstr_class+'_abstracts'\n",
    "\n",
    "            try:\n",
    "                os.mkdir(abstr_class_path)\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "         os.rename(f.name, abstr_class_path+os.sep+abstr_class+'_'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createWordCloud(words, stopwords):\n",
    "    wordcloud = WordCloud(max_words = 20, stopwords = stopwords)\n",
    "    wordcloud.generate(' '.join(words))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.figure()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class best_classifier(ClassifierI):\n",
    "    def __init__(self,*classifiers):\n",
    "        self.classifiers_ = classifiers \n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self.classifiers_:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self.classifiers_:\n",
    "            v = c.classify(features)\n",
    "        votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        confi = choice_votes/len(votes)\n",
    "        return confi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "physics_feed = search_abstracts('all:physics', start = 0, max_results = 1500)\n",
    "math_feed = search_abstracts('all:math', start = 0, max_results = 1500)\n",
    "\n",
    "physics_abstracts = [entry.summary for entry in physics_feed.entries]\n",
    "math_abstracts = [entry.summary for entry in math_feed.entries]\n",
    "\n",
    "physics_tokenized, phys_words = tokenize_abst('physics', physics_abstracts)\n",
    "math_tokenized, math_words = tokenize_abst('math', math_abstracts)\n",
    "\n",
    "all_words = phys_words + math_words\n",
    "all_abstracts = physics_tokenized + math_tokenized \n",
    "\n",
    "# shuffle all_abtracts\n",
    "random.shuffle(all_abstracts)\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "abstract_features = [(feature_selection(abst), area) for (abst, area) in all_abstracts]\n",
    "\n",
    "training_set = abstract_features[:2500]\n",
    "testing_set = abstract_features[2500:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Naive Bayes NLTK accurary percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classif = scikit_classifier('MultinomialNB', MultinomialNB, training_set, testing_set)\n",
    "BernoulliNB_classif = scikit_classifier('BernoulliNB', BernoulliNB, training_set, testing_set)\n",
    "LogisticRegr_classif = scikit_classifier('LogisticRegression', LogisticRegression, training_set, testing_set)\n",
    "SGD_classif = scikit_classifier('SGDClassifier', SGDClassifier, training_set, testing_set)\n",
    "LinearSVC_classif = scikit_classifier('LinearSVC', LinearSVC, training_set, testing_set)\n",
    "NuSVC_classif = scikit_classifier('NuSVC', NuSVC, training_set, testing_set)\n",
    "\n",
    "selected_classifier = best_classifier(classifier, MNB_classif, BernoulliNB_classif, LogisticRegr_classif, \n",
    "                                    SGD_classif, LinearSVC_classif, NuSVC_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Selected classifier accuracy percent:\", (nltk.classify.accuracy(selected_classifier, testing_set))*100)\n",
    "print(\"Classified:\", selected_classifier.classify(testing_set[0][0]), \"with\",\n",
    "\t  \"Confidence:\",selected_classifier.confidence(testing_set[0][0])*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = create_files()\n",
    "classify_abstract(path, selected_classifier)\n",
    "\n",
    "createWordCloud(phys_words, stop_words)\n",
    "createWordCloud(math_words, stop_words)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [snakes]",
   "language": "python",
   "name": "Python [snakes]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
